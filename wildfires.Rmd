---
title: "AAMEHS_finalproj"
author: "Maggie Li (ml4424)"
date: "2/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# load libraries
library(tidyverse)
library(leaflet)
library(sf)
library(janitor)
library(sp)
library(rgdal)
```

## Read in data

OLD Data source: https://data-nifc.opendata.arcgis.com/datasets/historic-perimeters-combined-2000-2018/data?geometry=-96.951%2C-9.831%2C-147.224%2C74.202&orderBy=perimeterdatetime&selectedAttribute=fireyear&where=state%20%3D%20%27CA%27

UPDATED data source: https://hub-calfire-forestry.hub.arcgis.com/datasets/california-fire-perimeters-all 

UPDATED Metadata:
alarm_date = first date of wildfire
cont_date = last date of wildfire (i.e. when it was contained)


```{r read in wildfire perimeter shapefile and filter 2011-2018}
wf_11_18_shp = st_read("data/cali_wildfires/California_Fire_Perimeters-shp/California_Fire_Perimeters__all_.shp") %>% 
  janitor::clean_names() %>%
  filter(year >= 2011,
         year <= 2018)
wf_11_18_shp

# reproject
wf_11_18_shp <- st_transform(wf_11_18_shp, 4326)

# Note: can probably just use CSV data (see below) for quantitative data manipulation and analysis (e.g. running summary stats and statistical models). shapefile is better for viz if we are including any maps.

# save separate shapefiles for each year
wf_11 = wf_11_18_shp %>% 
  filter(year == 2011)

# write out shapefile for each year
# st_write(wf_11, "data/cali_wildfires/California_Fire_Perimeters-shp/cali_wf_11.shp")

```


```{r read in wildfire perimeter csv spreedsheet}
wf_11_18 = read_csv("data/cali_wildfires/California_Fire_Perimeters.csv") %>% 
  janitor::clean_names() %>%
  filter(year >= 2011,
         year <= 2018)
view(wf_11_18)
```

## Summary Statistics

Bar graph: x-axis = year (year); y-axis = total acres burned (gis_acres)
```{r bar graph for area burned by wildfire 2011-2018}
wf_annual_burned = wf_11_18 %>% 
  mutate(year = as.character(year)) %>% 
  drop_na(gis_acres) %>% 
  group_by(year) %>% 
  summarize(sum(gis_acres)) %>% 
  rename(annual_burned = "sum(gis_acres)") 
view(wf_annual_burned)

ggplot(data = wf_annual_burned,
       aes(x = year, y = annual_burned)) +
  geom_bar(stat = "identity") + theme_linedraw()
  
```

```{r distribution of fire intensities}
# histogram of all wildfire sizes
wf_hist = ggplot(wf_11_18,
       aes(x = gis_acres)) +
  geom_histogram(bins = 30) +
  geom_density()
wf_hist

# histogram of Class G fires (largest)
wf_hist_classg = wf_11_18 %>% filter(gis_acres >= 5000) %>% 
  ggplot(aes(x = gis_acres)) +
  geom_histogram(bins = 30) +
  geom_density() 
  # + scale_x_continuous(trans='log2') 
wf_hist_classg

# boxplot showing distribution of Class G fires (largest)
wf_11_18 %>% filter(gis_acres >= 5000) %>% 
  ggplot(aes(x = year,
           y = gis_acres,
           group = year)) +
  geom_boxplot() + theme_linedraw()

# boxplot showing distribution of Class A-F fires (all other fires)
wf_11_18 %>% filter(gis_acres < 5000) %>% 
  ggplot(aes(x = year,
           y = gis_acres,
           group = year)) +
  geom_boxplot() + theme_linedraw()

# Note: want to include all data in the main analysis, since we hypothesize that smaller fires could still have a health impact on a local level (county level)
```

## Aggregating wildfire exposure at county level

### Testing on 2011 Wildfires

```{r join wildfire and CA county shapefile}
# read in county shapefile and filter only CA
ca_counties = st_read("data/cb_2018_us_county_500k/cb_2018_us_county_500k.shp") %>%
  filter(STATEFP == "06")

# check CRS
st_crs(wf_11)
st_crs(ca_counties) # different

# reproject ca_counties into the same CRS as wf
ca_counties <- st_transform(ca_counties, crs = 4326)

wf_counties_11 = st_join(ca_counties, wf_11, left = F) # dataframe contains rows for each county that contained a wildfire

wf_counties_11_18 = st_join(ca_counties, wf_11_18_shp, left = F)

```

```{r get tidied county-level wildfires}
# number of wildfires per county

# convert sf to dataframe
st_geometry(wf_counties_11) <- NULL
st_geometry(wf_counties_11_18) <- NULL

# summarize data by total acres burned and number of fires per county
wf_11_tidy = wf_counties_11 %>% 
  group_by(GEOID) %>% 
  summarize(sum(gis_acres), # total acres burned
            n()) # number of fires

wf_11_18_tidy = wf_counties_11_18 %>% 
  group_by(GEOID, year) %>% 
  summarize(sum(gis_acres), # total acres burned
            n()) # number of fires

write_csv(wf_11_18_tidy, 
          "data/wf_cleaned.csv")

```

