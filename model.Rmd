---
title: "results"
author: "Maggie Li (ml4424)"
date: "3/22/2021"
output: html_document
---

```{r}
library(tidyverse)
library(stats)
library(tableone)
library(sf)
library(tmap)
```


# Running statistical models

## Joining exposure, covariate, and outcome data

```{r read in datasets}
# exposure data: number of wildfires
wf_data = read_csv("data/wf_cleaned.csv") %>% 
  dplyr::select(-"sum(gis_acres)")

# exposure data: percent area burned per county
wf_percburn = read_csv("data/cali_wildfires/California_Fire_Perimeters-shp/intermediate/overlap/cleaned_wf_overlap.csv") %>%
  pivot_longer("2011":"2018",
               names_to = "year",
               values_to = "percent_burned") %>% 
  mutate(year = as.integer(year))
wf_percburn

# population offset
offset = read_csv("data/offset_data.csv") %>% 
  dplyr::select(GEOID, under_18, under_18_male, under_18_female)

# outcome data
asthma_data = read_csv("data/asthma_under18_cleaned.csv") %>% 
  dplyr::select(county_name, county, year, numerator) %>% 
  rename(GEOID = county) %>% 
  rename(County = county_name)

# covariates
temperature = read_csv("data/avg_summer_temp.csv") %>% 
  dplyr::select(Location, avg_temp, year)

precip = read_csv("data/annual_precip.csv") %>% 
  dplyr::select(Location, Value, year)

temp_precip = left_join(temperature, precip) %>% 
  rename(precip = Value) %>% 
  mutate(County = str_remove(string = Location, pattern = " County")) %>% # new column of all CA counties without "County" suffix
  select(-Location)

census_cov = read_csv("data/census_cov_cleaned.csv") %>% 
  dplyr::select(County, pct_urban, hshld_income, pop_density) %>% 
  rename(GEOID = County)

wf_data
wf_percburn
offset
asthma_data
temp_precip
census_cov
```



```{r create full dataset}
# first analysis with number of wildfires per county per year
full_data = left_join(asthma_data, temp_precip) %>% # note missing asthma ED data for least populous counties
  left_join(wf_data) %>% 
  left_join(offset) %>% 
  left_join(census_cov) %>% 
  rename(asthma_counts = numerator) %>% 
  rename(num_wfs = "n()") %>% 
  mutate(num_wfs = replace_na(num_wfs, 0)) %>%  # note: check NAs to make sure they mean no fires in the county that year
  na.omit()

View(full_data)

min(full_data$num_wfs)
max(full_data$num_wfs)
sd(full_data$num_wfs)
mean(full_data$num_wfs)
hist(full_data$num_wfs)

# second analysis with percent burned in county per year
full_data_percburn = left_join(asthma_data, temp_precip) %>% # note missing asthma ED data for least populous counties
  left_join(wf_percburn) %>% 
  left_join(offset) %>% 
  left_join(census_cov) %>% 
  rename(asthma_counts = numerator)
full_data_percburn

min(full_data_percburn$percent_burned)
max(full_data_percburn$percent_burned)
sd(full_data_percburn$percent_burned)
mean(full_data_percburn$percent_burned)
hist(full_data_percburn$percent_burned)
  
```
## Run quasipoisson mixed model

```{r reduced model}
# quasipoisson linear mixed effects regression
library(lme4)
library(MASS)
library(lqmm)
library(mgcv)
library(Qtools)

# CRUDE MODEL: number of wildfires
qp_glmm_crude = glmmPQL(asthma_counts ~ offset(I(log(under_18))) + num_wfs,
                  data = full_data,
                  random = ~ 1 | GEOID,
                family = quasipoisson(link = "log"))

# how to call summary outputs
summary(qp_glmm_crude)$tTable[,1] # effect estimates (betas)
summary(qp_glmm_crude)$tTable[,1][2] # effect estimate for wildfire beta
summary(qp_glmm_crude)$tTable[,2] # standard errors of betas
summary(qp_glmm_crude)$tTable[,2][2] # standard error of wildfire beta

# get RR for number of wildfire beta
# point estimate
exp(summary(qp_glmm_crude)$tTable[,1])[2]
# 95% CI
exp(summary(qp_glmm_crude)$tTable[,1][2] - 1.96*summary(qp_glmm_crude)$tTable[,2][2])
exp(summary(qp_glmm_crude)$tTable[,1][2] + 1.96*summary(qp_glmm_crude)$tTable[,2][2])


# CRUDE MODEL: percent area burned
qp_glmm_crude_percburn = glmmPQL(asthma_counts ~ offset(I(log(under_18))) + percent_burned,
                  data = full_data_percburn,
                  random = ~ 1 | GEOID,
                family = quasipoisson(link = "log"))

# how to call summary outputs
summary(qp_glmm_crude_percburn)$tTable[,1] # effect estimates (betas)
summary(qp_glmm_crude_percburn)$tTable[,1][2] # effect estimate for wildfire beta
summary(qp_glmm_crude_percburn)$tTable[,2] # standard errors of betas
summary(qp_glmm_crude_percburn)$tTable[,2][2] # standard error of wildfire beta

# get RR for number of wildfire beta
# point estimate
exp(summary(qp_glmm_crude_percburn)$tTable[,1])[2]
# 95% CI
exp(summary(qp_glmm_crude_percburn)$tTable[,1][2] - 1.96*summary(qp_glmm_crude_percburn)$tTable[,2][2])
exp(summary(qp_glmm_crude_percburn)$tTable[,1][2] + 1.96*summary(qp_glmm_crude_percburn)$tTable[,2][2])

```

```{r full model}
# FULL MODEL: number of wildfires
qp_glmm_full = glmmPQL(asthma_counts ~ offset(I(log(under_18))) + num_wfs + avg_temp + precip + pop_density + hshld_income,
                  data = full_data,
                  random = ~ 1 | GEOID,
                family = quasipoisson(link = "log"))

summary(qp_glmm_full)

# get RR for number of wildfire beta
# point estimate
exp(summary(qp_glmm_full)$tTable[,1])[2]
# 95% CI
exp(summary(qp_glmm_full)$tTable[,1][2] - 1.96*summary(qp_glmm_full)$tTable[,2][2])
exp(summary(qp_glmm_full)$tTable[,1][2] + 1.96*summary(qp_glmm_full)$tTable[,2][2])

# FULL MODEL: percent area burned
qp_glmm_full_percburn = glmmPQL(asthma_counts ~ offset(I(log(under_18))) + percent_burned + 
                                  avg_temp + precip + pop_density + hshld_income,
                  data = full_data_percburn,
                  random = ~ 1 | GEOID,
                family = quasipoisson(link = "log"))

summary(qp_glmm_full_percburn)

# get RR for number of wildfire beta
# point estimate
exp(summary(qp_glmm_full_percburn)$tTable[,1])[2]
# 95% CI
exp(summary(qp_glmm_full_percburn)$tTable[,1][2] - 1.96*summary(qp_glmm_full_percburn)$tTable[,2][2])
exp(summary(qp_glmm_full_percburn)$tTable[,1][2] + 1.96*summary(qp_glmm_full_percburn)$tTable[,2][2])

```

## Run quantile regression

```{r quantile regression on num wfs}

# Notes from Marianthi OH (3/23/21):

## Either assume continuous outcome for mixed quantile regression; or try rq.counts to have quasipoisson without random intercept (underestimating confidence interval)

# discuss limitation regardless; maybe try both!

# look at distribution of counts; if it "looks normal", maybe use lqmm and assume continuous outcome but if not this will be bad

# look at outcome distribution
hist(full_data$asthma_counts) # severely right skewed, try rq.counts first

# run rq.counts on 50th percentile
qr_rq.counts_median = rq.counts(asthma_counts ~ num_wfs + avg_temp + precip + 
                           pop_density + hshld_income,
                         data = full_data,
                         tau = 0.5,
                         offset = I(log(under_18)))

coef(qr_rq.counts_median)[2] # effect estimate of wildfires
qr_rq.counts_median$tTable[2,1] # also effect estimate of wildfires
qr_rq.counts_median$tTable[2,2]  # std error of wildfires

# get RRs and 95% CI
# point estimate
exp(qr_rq.counts_median$tTable[2,1])
# 95% CI
exp(qr_rq.counts_median$tTable[2,1] - 1.96*qr_rq.counts_median$tTable[2,2])
exp(qr_rq.counts_median$tTable[2,1] + 1.96*qr_rq.counts_median$tTable[2,2])


# run rq.counts on 25th percentile
qr_rq.counts_25 = rq.counts(asthma_counts ~ num_wfs + avg_temp + precip + 
                           pop_density + hshld_income,
                         data = full_data,
                         tau = 0.25,
                         offset = I(log(under_18)))

coef(qr_rq.counts_25)[2] # effect estimate of wildfires
qr_rq.counts_25$tTable[2,1] # also effect estimate of wildfires
qr_rq.counts_25$tTable[2,2]  # std error of wildfires

# get RRs and 95% CI
# point estimate
exp(qr_rq.counts_25$tTable[2,1])
# 95% CI
exp(qr_rq.counts_25$tTable[2,1] - 1.96*qr_rq.counts_25$tTable[2,2])
exp(qr_rq.counts_25$tTable[2,1] + 1.96*qr_rq.counts_25$tTable[2,2])

# run rq.counts on 75th percentile
qr_rq.counts_75 = rq.counts(asthma_counts ~ num_wfs + avg_temp + precip + 
                           pop_density + hshld_income,
                         data = full_data,
                         tau = 0.75,
                         offset = I(log(under_18)))

coef(qr_rq.counts_75)[2] # effect estimate of wildfires
qr_rq.counts_75$tTable[2,1] # also effect estimate of wildfires
qr_rq.counts_75$tTable[2,2]  # std error of wildfires

# get RRs and 95% CI
# point estimate
exp(qr_rq.counts_75$tTable[2,1])
# 95% CI
exp(qr_rq.counts_75$tTable[2,1] - 1.96*qr_rq.counts_75$tTable[2,2])
exp(qr_rq.counts_75$tTable[2,1] + 1.96*qr_rq.counts_75$tTable[2,2])

# TRY LQMM
# qp_quantile = lqmm(asthma_counts ~ num_wfs + avg_temp + precip + pop_density + hshld_income,
#                         data = full_data,
#                         ) # lqmm does not allow for poisson (generalized) nature

```

```{r quantile regression on perc area burned}
# run rq.counts on 50th percentile
qr_median_percburn = rq.counts(asthma_counts ~ percent_burned + avg_temp + precip + 
                           pop_density + hshld_income,
                         data = full_data_percburn,
                         tau = 0.5,
                         offset = I(log(under_18)))

coef(qr_median_percburn)[2] # effect estimate of wildfires
qr_median_percburn$tTable[2,1] # also effect estimate of wildfires
qr_median_percburn$tTable[2,2]  # std error of wildfires

# get RRs and 95% CI
# point estimate
exp(qr_median_percburn$tTable[2,1])
# 95% CI
exp(qr_median_percburn$tTable[2,1] - 1.96*qr_median_percburn$tTable[2,2])
exp(qr_median_percburn$tTable[2,1] + 1.96*qr_median_percburn$tTable[2,2])


# run rq.counts on 25th percentile
qr_25_percburn = rq.counts(asthma_counts ~ percent_burned + avg_temp + precip + 
                           pop_density + hshld_income,
                         data = full_data_percburn,
                         tau = 0.25,
                         offset = I(log(under_18)))

coef(qr_25_percburn)[2] # effect estimate of wildfires
qr_25_percburn$tTable[2,1] # also effect estimate of wildfires
qr_25_percburn$tTable[2,2]  # std error of wildfires

# get RRs and 95% CI
# point estimate
exp(qr_25_percburn$tTable[2,1])
# 95% CI
exp(qr_25_percburn$tTable[2,1] - 1.96*qr_25_percburn$tTable[2,2])
exp(qr_25_percburn$tTable[2,1] + 1.96*qr_25_percburn$tTable[2,2])

# run rq.counts on 75th percentile
qr_75_percburn = rq.counts(asthma_counts ~ percent_burned + avg_temp + precip + 
                           pop_density + hshld_income,
                         data = full_data_percburn,
                         tau = 0.75,
                         offset = I(log(under_18)))

coef(qr_75_percburn)[2] # effect estimate of wildfires
qr_75_percburn$tTable[2,1] # also effect estimate of wildfires
qr_75_percburn$tTable[2,2]  # std error of wildfires

# get RRs and 95% CI
# point estimate
exp(qr_75_percburn$tTable[2,1])
# 95% CI
exp(qr_75_percburn$tTable[2,1] - 1.96*qr_75_percburn$tTable[2,2])
exp(qr_75_percburn$tTable[2,1] + 1.96*qr_75_percburn$tTable[2,2])

```

# Table 1
```{r table 1}

#Get total number of wildfires per year
aggregate(full_data$num_wfs, by=list(year=full_data$year), FUN=sum)

#Get total number of asthma admissions per year
aggregate(full_data$asthma_counts, by=list(year=full_data$year), FUN=sum)

#Get asthma rates / county
full_data = full_data %>% 
mutate(asthma_rate = asthma_counts/under_18,
        asthma_rate = round(asthma_rate,2)
  )

#using tableone for wildfire count
factorVars = ("year")

## Create variable list. 
vars = c("asthma_rate","num_wfs","pop_density","hshld_income","avg_temp","precip")

tableone = CreateTableOne(vars = vars, strata = "year", data = full_data)

tableone

#using tableone for wildfire percent burned

## Create variable list. 
vars1 = c("percent_burned")

tableone_perc_burned = CreateTableOne(vars = vars1, strata = "year", data = full_data_percburn)

tableone_perc_burned
```

# Asthma Admission Chloropleth Map

```{r}
# read in CA counties shapefile
ca_counties_shp = st_read(
  "data/cb_2018_us_county_500k/cb_2018_us_county_500k.shp") %>% 
  filter(STATEFP == "06")
 
full_data_asthma_map = full_data %>% 
  mutate(asthma_rate = 100000 * asthma_counts/under_18) # make extra column to map
  
full_data_asthma_map_sf = merge(ca_counties_shp, full_data_asthma_map)

asthma_facet_choropleth = 
  tm_shape(ca_counties_shp) +
  tm_borders() +
  tm_shape(full_data_asthma_map_sf) +
  tm_polygons(col = "asthma_rate", border.col = "black", palette = "BuGn", 
          title = "Asthma ED admissions \n per 100,000 under age 18") +
  tm_facets(by = "year", nrow = 4, free.coords = FALSE)
asthma_facet_choropleth
ggsave("figures/asthma_facet_choropleth.png")
```

